# Airflow + Spark + Zeppelin Docker í™˜ê²½

ì´ í”„ë¡œì íŠ¸ëŠ” Dockerë¥¼ ì‚¬ìš©í•˜ì—¬ Apache Airflow, Apache Spark, Apache Zeppelinì„ í†µí•© í™˜ê²½ìœ¼ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤.

## ğŸš€ ì‹œì‘í•˜ê¸°

### 1. í”„ë¡œì íŠ¸ í´ë¡  ë° ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±

```bash
# í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p {dags,logs,plugins,data,scripts,zeppelin/notebook,zeppelin/conf}

# ê¶Œí•œ ì„¤ì • (Linux/macOS)
chmod 755 dags logs plugins data scripts
```

### 2. í™˜ê²½ ì‹œì‘

```bash
# ì»¨í…Œì´ë„ˆ ë¹Œë“œ ë° ì‹œì‘
docker-compose up -d

# ë¡œê·¸ í™•ì¸
docker-compose logs -f
```

### 3. ì„œë¹„ìŠ¤ ì ‘ì†

- **Airflow Web UI**: http://localhost:8080
  - Username: `admin`
  - Password: `admin`
- **Spark Master UI**: http://localhost:8081
- **Zeppelin**: http://localhost:8082

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
.
â”œâ”€â”€ docker-compose.yml          # ì „ì²´ ì„œë¹„ìŠ¤ êµ¬ì„±
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ Dockerfile             # Airflow ì»¤ìŠ¤í…€ ì´ë¯¸ì§€
â”‚   â”œâ”€â”€ requirements.txt       # Python íŒ¨í‚¤ì§€
â”‚   â””â”€â”€ entrypoint.sh          # ì´ˆê¸°í™” ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ dags/                      # Airflow DAG íŒŒì¼ë“¤
â”‚   â””â”€â”€ spark_example_dag.py   # ì˜ˆì œ DAG
â”œâ”€â”€ scripts/                   # Spark ì‘ì—… ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ spark_job.py          # ì˜ˆì œ Spark ì‘ì—…
â”œâ”€â”€ data/                      # ê³µìœ  ë°ì´í„° í´ë”
â”œâ”€â”€ logs/                      # Airflow ë¡œê·¸
â”œâ”€â”€ plugins/                   # Airflow í”ŒëŸ¬ê·¸ì¸
â”œâ”€â”€ zeppelin/
â”‚   â”œâ”€â”€ notebook/             # Zeppelin ë…¸íŠ¸ë¶
â”‚   â””â”€â”€ conf/                 # Zeppelin ì„¤ì •
â””â”€â”€ README.md
```

## ğŸ”§ ì£¼ìš” ê¸°ëŠ¥

### ê³µìœ  ë³¼ë¥¨
- `./data`: ëª¨ë“  ì»¨í…Œì´ë„ˆì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•œ ë°ì´í„° í´ë”
- `./scripts`: Spark ì‘ì—… ìŠ¤í¬ë¦½íŠ¸ í´ë”
- ì»¨í…Œì´ë„ˆ ê°„ íŒŒì¼ ê³µìœ ê°€ ìë™ìœ¼ë¡œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤

### Airflowì—ì„œ Spark ì‘ì—… ì‹¤í–‰
1. DAGì—ì„œ `SparkSubmitOperator` ì‚¬ìš©
2. ìŠ¤í¬ë¦½íŠ¸ëŠ” `/scripts` í´ë”ì— ì €ì¥
3. ë°ì´í„°ëŠ” `/data` í´ë”ì—ì„œ ê³µìœ 

### ì˜ˆì œ ì›Œí¬í”Œë¡œìš°
1. Pythonìœ¼ë¡œ ìƒ˜í”Œ ë°ì´í„° ìƒì„±
2. Sparkë¡œ ë°ì´í„° ì²˜ë¦¬
3. ê²°ê³¼ë¥¼ ê³µìœ  í´ë”ì— ì €ì¥

## ğŸ“Š ì‚¬ìš© ì˜ˆì œ

### Airflow DAG ì‹¤í–‰
1. Airflow UIì—ì„œ `spark_example_dag` ì°¾ê¸°
2. DAG í™œì„±í™”
3. ìˆ˜ë™ ì‹¤í–‰ ë˜ëŠ” ìŠ¤ì¼€ì¤„ ëŒ€ê¸°

### Zeppelinì—ì„œ Spark ì‚¬ìš©
```scala
%spark
val df = spark.read.option("header", "true").csv("/opt/zeppelin/data/sample_data.csv")
df.show()
```

## ğŸ›  ê°œë°œ ê°€ì´ë“œ

### ìƒˆë¡œìš´ Spark ì‘ì—… ì¶”ê°€
1. `/scripts` í´ë”ì— Python íŒŒì¼ ìƒì„±
2. DAGì—ì„œ `SparkSubmitOperator`ë¡œ ì‹¤í–‰
3. ë°ì´í„°ëŠ” `/data` í´ë” ì‚¬ìš©

### ì»¤ìŠ¤í…€ íŒ¨í‚¤ì§€ ì¶”ê°€
1. `airflow/requirements.txt`ì— íŒ¨í‚¤ì§€ ì¶”ê°€
2. ì»¨í…Œì´ë„ˆ ì¬ë¹Œë“œ: `docker-compose build airflow-webserver`

## ğŸ” íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
```bash
docker-compose ps
```

### ë¡œê·¸ í™•ì¸
```bash
# íŠ¹ì • ì„œë¹„ìŠ¤ ë¡œê·¸
docker-compose logs spark-master
docker-compose logs airflow-webserver

# ì‹¤ì‹œê°„ ë¡œê·¸
docker-compose logs -f
```

### ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
```bash
docker-compose down -v
docker-compose up -d
```

## ğŸ“‹ ìš”êµ¬ì‚¬í•­

- Docker & Docker Compose
- ìµœì†Œ 4GB RAM ê¶Œì¥
- í¬íŠ¸ 8080, 8081, 8082 ì‚¬ìš© ê°€ëŠ¥

## ğŸ”§ ì„¤ì • ë³€ê²½

### Spark ì›Œì»¤ ë¦¬ì†ŒìŠ¤ ì¡°ì •
`docker-compose.yml`ì—ì„œ í™˜ê²½ë³€ìˆ˜ ìˆ˜ì •:
```yaml
environment:
  - SPARK_WORKER_MEMORY=4g
  - SPARK_WORKER_CORES=4
```

### Airflow ì„¤ì • ë³€ê²½
`docker-compose.yml`ì˜ í™˜ê²½ë³€ìˆ˜ ì„¹ì…˜ì—ì„œ Airflow ì„¤ì • ìˆ˜ì • ê°€ëŠ¥# meta-airflow
